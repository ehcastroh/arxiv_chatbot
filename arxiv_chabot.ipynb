{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bea3937",
   "metadata": {},
   "source": [
    "# Arxiv Chatbot\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project implements a chatbot system with integrated tool definitions and execution. The chatbot is designed as a simple but extensible example for understanding how conversational AI can be augmented with tools, via model context protocol (MCP) to perform tasks beyond basic dialogue.\n",
    "\n",
    "To interact with chatbot from terminal, run `arxiv_chatbot.py` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d0d981",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96367f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e587f",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41558b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name where paper metadata will be stored\n",
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca9c3f",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the papers directory. The tool does not download the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd116c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "    Args:\n",
    "        topic (str): The topic/keyword to search for.\n",
    "        max_results (int, optional): Maximum number of results to retrieve. \n",
    "            Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of arXiv paper IDs found in the search.\n",
    "\n",
    "    Side Effects:\n",
    "        - Creates a directory under PAPER_DIR named after the topic.\n",
    "        - Updates (or creates) a `papers_info.json` file with metadata of retrieved papers.\n",
    "        - Prints the path where results are saved.\n",
    "    \"\"\"\n",
    "    # Initialize arXiv API client\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Define search query\n",
    "    search = arxiv.Search(\n",
    "        query=topic,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance,\n",
    "    )\n",
    "\n",
    "    # Execute the search\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create a subdirectory for the topic (e.g., \"machine_learning/\")\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Path to the JSON file storing paper metadata\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Load existing metadata (if any); start fresh otherwise\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Collect paper metadata and update dictionary\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_id = paper.get_short_id()\n",
    "        paper_ids.append(paper_id)\n",
    "\n",
    "        papers_info[paper_id] = {\n",
    "            \"title\": paper.title,\n",
    "            \"authors\": [author.name for author in paper.authors],\n",
    "            \"summary\": paper.summary,\n",
    "            \"pdf_url\": paper.pdf_url,\n",
    "            \"published\": str(paper.published.date()),\n",
    "        }\n",
    "\n",
    "    # Save updated metadata to JSON file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f019baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers\\mcp_transport\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2504.08999v1',\n",
       " '2508.13220v1',\n",
       " '2508.19239v1',\n",
       " '2409.10254v2',\n",
       " '2004.04606v1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"mcp transport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f6cfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve stored metadata for a specific paper by ID.\n",
    "\n",
    "    This function searches through all topic subdirectories in PAPER_DIR, \n",
    "    looking for a `papers_info.json` file that contains information about \n",
    "    the requested paper. If found, the paper's metadata is returned as a \n",
    "    formatted JSON string.\n",
    "\n",
    "    Args:\n",
    "        paper_id (str): The arXiv short ID of the paper to look up \n",
    "            (e.g., \"2501.01234\").\n",
    "\n",
    "    Returns:\n",
    "        str: JSON-formatted string with the paper's metadata if found. \n",
    "             Otherwise, a human-readable error message.\n",
    "\n",
    "    Side Effects:\n",
    "        - Prints error messages if a `papers_info.json` file cannot be read.\n",
    "\n",
    "    Notes:\n",
    "        - Paper metadata must have been previously saved by `search_papers`.\n",
    "        - Metadata includes title, authors, summary, pdf_url, and publication date.\n",
    "    \"\"\"\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "\n",
    "        # Only process directories (topic folders)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "\n",
    "                        # If paper is found, return its metadata as formatted JSON\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c61586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers\",\\n  \"authors\": [\\n    \"Arash Ahmadi\",\\n    \"Sarah Sharif\",\\n    \"Yaser M. Banad\"\\n  ],\\n  \"summary\": \"Large Language Models (LLMs) are increasingly augmented with external tools\\\\nthrough standardized interfaces like the Model Context Protocol (MCP). However,\\\\ncurrent MCP implementations face critical limitations: they typically require\\\\nlocal process execution through STDIO transports, making them impractical for\\\\nresource-constrained environments like mobile devices, web browsers, and edge\\\\ncomputing. We present MCP Bridge, a lightweight RESTful proxy that connects to\\\\nmultiple MCP servers and exposes their capabilities through a unified API.\\\\nUnlike existing solutions, MCP Bridge is fully LLM-agnostic, supporting any\\\\nbackend regardless of vendor. The system implements a risk-based execution\\\\nmodel with three security levels standard execution, confirmation workflow, and\\\\nDocker isolation while maintaining backward compatibility with standard MCP\\\\nclients. Complementing this server-side infrastructure is a Python based MCP\\\\nGemini Agent that facilitates natural language interaction with MCP tools. The\\\\nevaluation demonstrates that MCP Bridge successfully addresses the constraints\\\\nof direct MCP connections while providing enhanced security controls and\\\\ncross-platform compatibility, enabling sophisticated LLM-powered applications\\\\nin previously inaccessible environments\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/2504.08999v1\",\\n  \"published\": \"2025-04-11\"\\n}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "extract_info('2504.08999v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417b3ae",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861e6e6",
   "metadata": {},
   "source": [
    "The `tools` list defines metadata for each function you want the LLM to call (`search_papers` and `extract_info`). Each entry describes:\n",
    "\n",
    "1. What the tool does (`name` + `description`).\n",
    "\n",
    "2. What inputs it requires (`input_schema`).\n",
    "\n",
    "3. Which inputs are mandatory (`required`).\n",
    "\n",
    "This schema acts like an API contract between the LLM and the Python functions, so the model knows how to call each tool correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81c38ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64f40d",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af3027ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa135567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool(tool_name: str, tool_args: dict) -> str:\n",
    "    \"\"\"\n",
    "    Execute a registered tool function by name with provided arguments.\n",
    "\n",
    "    This function serves as a generic dispatcher for invoking tools defined \n",
    "    in `mapping_tool_function`. It ensures results are normalized into \n",
    "    human-readable strings for consistent handling by the chatbot or LLM.\n",
    "\n",
    "    Args:\n",
    "        tool_name (str): The name of the tool to execute. Must be a key in \n",
    "            `mapping_tool_function`.\n",
    "        tool_args (dict): A dictionary of arguments to pass to the tool. \n",
    "            Arguments are unpacked into keyword arguments.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the tool's result, normalized as follows:\n",
    "            - None → \"The operation completed but didn't return any results.\"\n",
    "            - List → Comma-separated string of items\n",
    "            - Dict → JSON-formatted string\n",
    "            - Any other type → Converted using str()\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the provided `tool_name` is not found in `mapping_tool_function`.\n",
    "    \"\"\"\n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        return \"The operation completed but didn't return any results.\"\n",
    "\n",
    "    if isinstance(result, list):\n",
    "        return \", \".join(result)\n",
    "\n",
    "    if isinstance(result, dict):\n",
    "        return json.dumps(result, indent=2)\n",
    "\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bc077",
   "metadata": {},
   "source": [
    "## Chatbot Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719a9cb",
   "metadata": {},
   "source": [
    "The chabot handles queries on a case by case basis. No memory is persistent across queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ac137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "client = anthropic.Anthropic(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb56c8",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37e080f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query: str) -> None:\n",
    "    \"\"\"\n",
    "    Process a user query by interacting with the LLM and handling tool calls.\n",
    "\n",
    "    This function sends the user's query to the LLM, monitors the response, \n",
    "    and executes tool calls when requested. It runs in a loop until the \n",
    "    assistant provides a final textual response.\n",
    "\n",
    "    Args:\n",
    "        query (str): The natural language query provided by the user.\n",
    "\n",
    "    Behavior:\n",
    "        - Sends the query and conversation history to the LLM.\n",
    "        - Handles assistant text responses (prints them to stdout).\n",
    "        - Detects tool call requests, executes the tool, and passes results \n",
    "          back into the conversation for the model to use.\n",
    "        - Continues looping until the conversation naturally concludes.\n",
    "\n",
    "    Notes:\n",
    "        - Tools must be defined in the global `tools` schema.\n",
    "        - Tool implementations must be mapped in `mapping_tool_function`.\n",
    "        - The function prints outputs directly (does not return them).\n",
    "\n",
    "    \"\"\"\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "\n",
    "    # Initial request to the model\n",
    "    response = client.messages.create(\n",
    "        max_tokens=2024,\n",
    "        model='claude-3-7-sonnet-20250219',\n",
    "        tools=tools,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response.content:\n",
    "\n",
    "            # Case A: Assistant responds with plain text\n",
    "            if content.type == 'text':\n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "\n",
    "                # End loop if this is the only content\n",
    "                if len(response.content) == 1:\n",
    "                    process_query = False\n",
    "\n",
    "            # Case B: Assistant requests a tool\n",
    "            elif content.type == 'tool_use':\n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "\n",
    "                # Extract tool call details\n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "\n",
    "                # Execute tool and feed result back into conversation\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_id,\n",
    "                            \"content\": result\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "                # Continue conversation with tool results\n",
    "                response = client.messages.create(\n",
    "                    max_tokens=2024,\n",
    "                    model='claude-3-7-sonnet-20250219',\n",
    "                    tools=tools,\n",
    "                    messages=messages\n",
    "                )\n",
    "\n",
    "                # If the model follows up only with text, end loop\n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d0434",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "217f7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop() -> None:\n",
    "    \"\"\"\n",
    "    Start an interactive command-line chat session with the chatbot.\n",
    "\n",
    "    This function runs a continuous loop where the user can type queries, \n",
    "    which are processed by the chatbot via `process_query`. The loop \n",
    "    terminates when the user types 'quit'.\n",
    "\n",
    "    Behavior:\n",
    "        - Prompts the user for input.\n",
    "        - Passes queries to `process_query` for handling.\n",
    "        - Prints chatbot responses to the console.\n",
    "        - Handles errors gracefully without terminating the session.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "\n",
    "            # Exit condition\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "\n",
    "            # Process query through chatbot pipeline\n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534550f",
   "metadata": {},
   "source": [
    "### Interact with Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f938c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Hello! I'm here to help you search for and extract information about academic papers on arXiv. You can ask me to:\n",
      "\n",
      "1. Search for papers on a specific topic\n",
      "2. Extract detailed information about a specific paper using its arXiv ID\n",
      "\n",
      "What would you like to know about? You can ask something like \"Find papers about quantum computing\" or \"Get information on paper 2104.12345\".\n",
      "\n",
      "\n",
      "I'll search for papers on \"MCP Transport\" for you. Let me use the search tool to find relevant papers on this topic.\n",
      "Calling tool search_papers with args {'topic': 'MCP Transport'}\n",
      "Results are saved in: papers\\mcp_transport\\papers_info.json\n",
      "I've found 5 papers related to \"MCP Transport\". Let me retrieve more detailed information about each of these papers to provide you with a better understanding of their content.\n",
      "Calling tool extract_info with args {'paper_id': '2504.08999v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2508.13220v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2508.19239v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2409.10254v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2004.04606v1'}\n",
      "Based on my search, I've found 5 papers related to \"MCP Transport\". Here's a summary of each:\n",
      "\n",
      "1. **MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers** (April 2025)\n",
      "   - Authors: Arash Ahmadi, Sarah Sharif, Yaser M. Banad\n",
      "   - Focuses on a RESTful proxy for Model Context Protocol (MCP) servers that enables connections across various platforms including resource-constrained environments\n",
      "   - Implements a risk-based execution model with three security levels\n",
      "\n",
      "2. **MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols** (August 2025)\n",
      "   - Authors: Yixuan Yang, Daoyuan Wu, Yufan Chen\n",
      "   - Presents a security benchmark for testing Model Context Protocols\n",
      "   - Identifies 17 attack types across 4 primary attack surfaces in MCP implementations\n",
      "\n",
      "3. **Model Context Protocols in Adaptive Transport Systems: A Survey** (August 2025)\n",
      "   - Authors: Gaurab Chhetri and 7 others\n",
      "   - A comprehensive survey on Model Context Protocols in transport systems\n",
      "   - Proposes a five-category taxonomy and positions MCP as a foundation for next-generation adaptive transport infrastructures\n",
      "\n",
      "4. **Exploring Multifractal Critical Phases in Two-Dimensional Quasiperiodic Systems** (September 2024)\n",
      "   - Authors: Chao Yang, Weizhe Yang, Yongjian Wang, Yucheng Wang\n",
      "   - Studies Multifractal Critical Phase (MCP) in a two-dimensional quasiperiodic model\n",
      "   - Investigates wave packet diffusion and transport characteristics in this system\n",
      "\n",
      "5. **The coupling of matter and spacetime geometry** (April 2020)\n",
      "   - Authors: Jose Beltran Jimenez, Lavinia Heisenberg, Tomi Koivisto\n",
      "   - Discusses the minimal coupling principle (MCP) in the context of gravitational theory\n",
      "   - Examines how MCP applies to Standard Model gauge fields and matter fields in affine geometry\n",
      "\n",
      "Interestingly, \"MCP\" has different meanings across these papers, including \"Model Context Protocol\" in papers 1-3, \"Multifractal Critical Phase\" in paper 4, and \"minimal coupling principle\" in paper 5. The transport aspects are addressed differently in each, with some focusing on data transport protocols and others on physical transport phenomena.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conversation\n",
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac1f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".arxivvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
